import cv2
import mediapipe as mp

# Initialize MediaPipe Hands
# mp_hands.Hands() creates an object that will detect hands.
# static_image_mode=False means it will treat the input as a video stream,
# which is more suitable for real-time webcam input.
# max_num_hands=1 means it will detect up to one hand.
# min_detection_confidence=0.5 sets the minimum confidence value for hand detection.
# min_tracking_confidence=0.5 sets the minimum confidence value for hand tracking.
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(static_image_mode=False,
                       max_num_hands=1,
                       min_detection_confidence=0.5,
                       min_tracking_confidence=0.5)

# Initialize MediaPipe Drawing utilities
# This will help us draw the hand landmarks on the image.
mp_drawing = mp.solutions.drawing_utils

# Open the webcam
# 0 typically refers to the default webcam. If you have multiple cameras,
# you might need to try 1, 2, etc.
cap = cv2.VideoCapture(0)

# Check if the webcam opened successfully
if not cap.isOpened():
    print("Error: Could not open webcam.")
    exit()

print("Webcam opened successfully. Press 'q' to quit.")

while True:
    # Read a frame from the webcam
    # ret is a boolean indicating if the frame was read successfully.
    # frame is the actual image frame.
    ret, frame = cap.read()
    if not ret:
        print("Failed to grab frame.")
        break

    # Flip the frame horizontally for a mirror effect (optional, but common for webcams)
    frame = cv2.flip(frame, 1)

    # Convert the BGR image to RGB
    # MediaPipe expects RGB images. OpenCV reads BGR by default.
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Process the frame to find hand landmarks
    # results will contain the detected hand landmarks if any.
    results = hands.process(rgb_frame)

    # Draw hand landmarks if detected
    if results.multi_hand_landmarks:
        for hand_landmarks in results.multi_hand_landmarks:
            # Draw the landmarks (circles) and connections (lines) on the frame
            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

            # You can access specific landmarks like this:
            # For example, the wrist landmark is at index 0.
            # print(f"Wrist X: {hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x}")
            # print(f"Wrist Y: {hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y}")

    # Display the frame
    cv2.imshow('Hand Tracking Test', frame)

    # Wait for a key press and check if it's 'q' (for quit)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the webcam and destroy all OpenCV windows
cap.release()
cv2.destroyAllWindows()
print("Webcam closed. Application terminated.")